
{"cells":[{"cell_type":"markdown","id":"499f884d","metadata":{"id":"499f884d"},"source":["# UNIT 3: Learning to Classify Text"]},{"cell_type":"markdown","id":"e14e2091","metadata":{"id":"e14e2091"},"source":["Detecting patterns is a central part of Natural Language Processing. Words ending in **-ed** tend to be past tense\n","verbs. Frequent use of will is indicative of news text. These observable patterns — word structure and\n","word frequency — happen to correlate with particular aspects of meaning, such as tense and topic. But how\n","did we know where to start looking, which aspects of form to associate with which aspects of meaning?\n","The goal of this chapter is to answer the following questions:\n","\n","1. How can we identify particular features of language data that are salient for classifying it?\n","\n","2. How can we construct models of language that can be used to perform language processing tasks\n","automatically?\n","\n","3. What can we learn about language from these models?\n","\n","Along the way we will study some important machine learning techniques, We will gloss over the mathematical and statistical\n","underpinnings of these techniques, focusing instead on how and when to use them"]},{"cell_type":"markdown","id":"7214b14e","metadata":{"id":"7214b14e"},"source":["# 1 Supervised Classification\n","\n","Classification is the task of choosing the correct class label for a given input. In basic classification tasks,\n","each input is considered in isolation from all other inputs, and the set of labels is defined in advance. Some\n","examples of classification tasks are:\n","\n","Deciding whether an email is spam or not.\n","\n","Deciding what the topic of a news article is, from a fixed list of topic areas such as \"sports,\"\n","\"technology,\" and \"politics.\"\n","\n","Deciding whether a given occurrence of the word bank is used to refer to a river bank, a financial\n","institution, the act of tilting to the side, or the act of depositing something in a financial institution.\n","\n","The basic classification task has a number of interesting variants. For example, in multi-class classification,\n","each instance may be assigned multiple labels; in open-class classification, the set of labels is not defined in\n","advance; and in sequence classification, a list of inputs are jointly classified.\n","A classifier is called supervised if it is built based on training corpora containing the correct label for each\n","input. The framework used by supervised classification is shown below:"]},{"cell_type":"markdown","id":"c69c4cdd","metadata":{"id":"c69c4cdd"},"source":["In the rest of this section, we will look at how classifiers can be employed to solve a wide variety of tasks.\n","Our discussion is not intended to be comprehensive, but to give a representative sample of tasks that can be\n","performed with the help of text classifiers.\n"]},{"cell_type":"markdown","id":"a70799fc","metadata":{"id":"a70799fc"},"source":["# 1.1 Gender Identification\n","\n","Names ending in **a, e and i are\n","likely to be female, while names ending in k, o, r, s and t are likely to be male.**\n","\n","Let's build a classifier to\n","model these differences more precisely.\n","\n","The first step in creating a classifier is deciding what features of the input are relevant, and how to encode\n","those features. For this example, we'll start by just looking at the final letter of a given name.\n","\n","The following\n","feature extractor function builds a dictionary containing relevant information about a given name:"]},{"cell_type":"code","execution_count":1,"id":"e9c4d79c","metadata":{"id":"e9c4d79c","outputId":"5cc6f6fb-b38c-41bd-b61a-5a29f575ba70","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712078213311,"user_tz":-330,"elapsed":9,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'last_letter': 'k'}"]},"metadata":{},"execution_count":1}],"source":["def gender_features(word):\n","    return {'last_letter': word[-1]}#The function returns a dictionary containing a single feature,\n","#where the key is 'last_letter',\n","#and the value is the last letter of the input word (word[-1]).\n","gender_features('Shrek')"]},{"cell_type":"markdown","id":"76137437","metadata":{"id":"76137437"},"source":["The returned dictionary, known as a feature set, maps from feature names to their values. Feature names are\n","case-sensitive strings that typically provide a short human-readable description of the feature, as in the\n","example 'last_letter'. Feature values are values with simple types, such as booleans, numbers, and strings.\n","\n","Now that we've defined a feature extractor, we need to prepare a list of examples and corresponding class\n","labels.\n","\n","Thus, the following code creates a list of labeled names by pairing each name from the 'male.txt' file with the label 'male' and each name from the 'female.txt' file with the label 'female'. The resulting list is then shuffled randomly.\n"]},{"cell_type":"code","execution_count":3,"id":"22a60765","metadata":{"id":"22a60765","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1712078229952,"user_tz":-330,"elapsed":393,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}},"outputId":"63ae553c-0aef-4dd1-dc3a-8ae0acae5cdc"},"outputs":[{"output_type":"error","ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names.zip/names/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8ac9165d3b7e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n\u001b[0m\u001b[1;32m      3\u001b[0m [(name, 'female') for name in names.words('female.txt')])\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;31m#This line imports the random module, which provides functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#for generating random numbers and performing random operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"]}],"source":["from nltk.corpus import names\n","labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n","[(name, 'female') for name in names.words('female.txt')])\n","import random #This line imports the random module, which provides functions\n","#for generating random numbers and performing random operations.\n","random.shuffle(labeled_names)"]},{"cell_type":"markdown","id":"e672b161","metadata":{"id":"e672b161"},"source":["Next, we use the feature extractor to process the names data, and divide the resulting list of feature sets into a\n","training set and a test set. The training set is used to train a new \"naive Bayes\" classifier.\n"]},{"cell_type":"code","execution_count":null,"id":"784cca98","metadata":{"id":"784cca98","executionInfo":{"status":"aborted","timestamp":1712078216401,"user_tz":-330,"elapsed":36,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["import nltk\n","featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n","train_set, test_set = featuresets[500:], featuresets[:500]\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n"]},{"cell_type":"markdown","id":"50c4769d","metadata":{"id":"50c4769d"},"source":["We will learn more about the naive Bayes classifier later in the chapter. For now, let's just test it out on some\n","names that did not appear in its training data:"]},{"cell_type":"code","execution_count":null,"id":"368dd40f","metadata":{"id":"368dd40f","executionInfo":{"status":"aborted","timestamp":1712078216401,"user_tz":-330,"elapsed":36,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["classifier.classify(gender_features('Neo'))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"1c577726","metadata":{"id":"1c577726","executionInfo":{"status":"aborted","timestamp":1712078216402,"user_tz":-330,"elapsed":36,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["classifier.classify(gender_features('Trinity'))"]},{"cell_type":"markdown","id":"85c46c75","metadata":{"id":"85c46c75"},"source":["Observe that these character names from The Matrix are correctly classified. Although this science fiction\n","movie is set in 2199, it still conforms with our expectations about names and genders. We can systematically\n","evaluate the classifier on a much larger quantity of unseen data:"]},{"cell_type":"code","execution_count":null,"id":"7611ac82","metadata":{"id":"7611ac82","executionInfo":{"status":"aborted","timestamp":1712078216402,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":[" print(nltk.classify.accuracy(classifier, test_set))\n"]},{"cell_type":"markdown","id":"306a475d","metadata":{"id":"306a475d"},"source":["Finally, we can examine the classifier to determine which features it found most effective for distinguishing\n","the names' genders:\n"]},{"cell_type":"code","execution_count":null,"id":"054e9411","metadata":{"id":"054e9411","executionInfo":{"status":"aborted","timestamp":1712078216402,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["classifier.show_most_informative_features(10)"]},{"cell_type":"markdown","id":"6dfc133a","metadata":{"id":"6dfc133a"},"source":["NOTE:\n","\n","In this example, the classifier is making predictions based on the last letter of names. The output shows the most informative features, the corresponding last letter, and the weight associated with each feature. For instance, if the last letter is 'a', the classifier is 35.7 times more likely to predict 'female' compared to 'male'. Similarly, if the last letter is 'k', the classifier is 31.2 times more likely to predict 'male' compared to 'female'.\n","\n","In other words, This listing shows that the names in the training set that end in \"a\" are female 33 times more often than they\n","are male, but names that end in \"k\" are male 32 times more often than they are female. These ratios are\n","known as likelihood ratios, and can be useful for comparing different feature-outcome relationships."]},{"cell_type":"markdown","id":"3745fd3c","metadata":{"id":"3745fd3c"},"source":["When working with large corpora, constructing a single list that contains the features of every instance can\n","use up a large amount of memory. In these cases, use the function nltk.classify.apply_features, which\n","returns an object that acts like a list but does not store all the feature sets in memory:"]},{"cell_type":"code","execution_count":null,"id":"9a0d1641","metadata":{"id":"9a0d1641","executionInfo":{"status":"aborted","timestamp":1712078216403,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["from nltk.classify import apply_features\n","train_set = apply_features(gender_features, labeled_names[500:])\n","test_set = apply_features(gender_features, labeled_names[:500])\n"]},{"cell_type":"markdown","id":"48f0a5e5","metadata":{"id":"48f0a5e5"},"source":["# 1.2 Choosing The Right Features\n","Selecting relevant features and deciding how to encode them for a learning method can have an enormous\n","impact on the learning method's ability to extract a good model. Much of the interesting work in building a\n","classifier is deciding what features might be relevant, and how we can represent them. Although it's often\n","possible to get decent performance by using a fairly simple and obvious set of features, there are usually\n","significant gains to be had by using carefully constructed features based on a thorough understanding of the\n","task at hand.\n","\n","Typically, feature extractors are built through a process of trial-and-error, guided by intuitions about what\n","information is relevant to the problem. It's common to start with a \"kitchen sink\" approach, including all the\n","features that you can think of, and then checking to see which features actually are helpful."]},{"cell_type":"code","execution_count":null,"id":"3f79b620","metadata":{"id":"3f79b620","executionInfo":{"status":"aborted","timestamp":1712078216403,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["def gender_features2(name):\n","    features = {}\n","    features[\"first_letter\"] = name[0].lower()\n","    features[\"last_letter\"] = name[-1].lower()\n","    for letter in 'abcdefghijklmnopqrstuvwxyz':\n","        features[\"count({})\".format(letter)] = name.lower().count(letter)\n","        features[\"has({})\".format(letter)] = (letter in name.lower())\n","    return features"]},{"cell_type":"code","execution_count":null,"id":"b2632149","metadata":{"id":"b2632149","executionInfo":{"status":"aborted","timestamp":1712078216403,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":[" gender_features2('Suhana')"]},{"cell_type":"markdown","id":"d0727813","metadata":{"id":"d0727813"},"source":["However, there are usually limits to the number of features that you should use with a given learning\n","algorithm — if you provide too many features, then the algorithm will have a higher chance of relying on\n","idiosyncrasies (a mode of behaviour) of your training data that don't generalize well to new examples. This problem is known as\n","overfitting, and can be especially problematic when working with small training sets.\n","\n","For example, if we\n","train a naive Bayes classifier using the feature extractor shown in 1.2, it will overfit the relatively small\n","training set, resulting in a system whose accuracy is about 1% lower than the accuracy of a classifier that\n","only pays attention to the final letter of each name:"]},{"cell_type":"code","execution_count":null,"id":"ba11065d","metadata":{"id":"ba11065d","executionInfo":{"status":"aborted","timestamp":1712078216404,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n","train_set, test_set = featuresets[500:], featuresets[:500]\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","print(nltk.classify.accuracy(classifier, test_set))\n"]},{"cell_type":"markdown","id":"d206324b","metadata":{"id":"d206324b"},"source":["Once an initial set of features has been chosen, a very productive method for refining the feature set is **error\n","analysis**. First, we select a development set, containing the corpus data for creating the model. This\n","development set is then subdivided into the training set and the dev-test set."]},{"cell_type":"code","execution_count":null,"id":"ab490b72","metadata":{"id":"ab490b72","executionInfo":{"status":"aborted","timestamp":1712078216404,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["train_names = labeled_names[1500:]\n","devtest_names = labeled_names[500:1500]\n","test_names = labeled_names[:500]"]},{"cell_type":"markdown","id":"a740e3ee","metadata":{"id":"a740e3ee"},"source":["The training set is used to train the model, and the dev-test set is used to perform error analysis. The test set\n","serves in our final evaluation of the system. For reasons discussed below, it is important that we employ a\n","separate dev-test set for error analysis, rather than just using the test set.\n","\n","![Untitled.png](attachment:Untitled.png)"]},{"cell_type":"markdown","id":"b654fdfe","metadata":{"id":"b654fdfe"},"source":["Having divided the corpus into appropriate datasets, we train a model using the training set , and then run it\n","on the dev-test set."]},{"cell_type":"code","execution_count":null,"id":"28fe3bc5","metadata":{"id":"28fe3bc5","executionInfo":{"status":"aborted","timestamp":1712078216405,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n","devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n","test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","print(nltk.classify.accuracy(classifier, devtest_set))"]},{"cell_type":"markdown","id":"c1240b1b","metadata":{"id":"c1240b1b"},"source":["Using the dev-test set, we can generate a list of the errors that the classifier makes when predicting name\n","genders:\n"]},{"cell_type":"code","execution_count":null,"id":"97c04800","metadata":{"id":"97c04800","executionInfo":{"status":"aborted","timestamp":1712078216405,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["errors = []\n","for (name, tag) in devtest_names:\n","    guess = classifier.classify(gender_features(name))\n","    if guess != tag:\n","        errors.append( (tag, guess, name) )\n","print(errors)"]},{"cell_type":"markdown","id":"a2202a89","metadata":{"id":"a2202a89"},"source":["We can then examine individual error cases where the model predicted the wrong label, and try to determine\n","what additional pieces of information would allow it to make the right decision (or which existing pieces of\n","information are tricking it into making the wrong decision). The feature set can then be adjusted accordingly.\n","The names classifier that we have built generates about 100 errors on the dev-test corpus:\n"]},{"cell_type":"code","execution_count":null,"id":"7c3f2af0","metadata":{"id":"7c3f2af0","executionInfo":{"status":"aborted","timestamp":1712078216405,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["for (tag, guess, name) in sorted(errors):\n","    print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))\n"]},{"cell_type":"markdown","id":"44cfb90e","metadata":{"id":"44cfb90e"},"source":["**Detailed Explanation:**\n","\n","Print Formatted Information:\n","\n","For each error tuple, it prints a formatted string using the print statement.\n","The format string 'correct={:<8} guess={:<8s} name={:<30}' specifies how the information should be formatted:\n","\n","{:<8}: Left-align the first element (actual label tag) within an 8-character wide space.\n","\n","{:<8s}: Left-align the second element (predicted label guess) within an 8-character wide space (with 's' indicating that it's a string).\n","\n","{:<30}: Left-align the third element (name name) within a 30-character wide space.\n","\n","The format method substitutes these placeholders with the corresponding values from the error tuple.\n","\n","In summary, this code iterates through the sorted list of errors and prints information about each error in a neatly formatted way. This information includes the actual label (tag), predicted label (guess), and the name (name). The formatting ensures that the output is aligned and easy to read. This type of output is helpful for analyzing the patterns of errors made by the classifier during testing."]},{"cell_type":"markdown","id":"12a3d61c","metadata":{"id":"12a3d61c"},"source":["Looking through this list of errors makes it clear that some suffixes that are more than one letter can be\n","indicative of name genders. For example, names ending in **yn appear to be predominantly female, despite the\n","fact that names ending in n tend to be male; and names ending in ch are usually male, even though names that\n","end in h tend to be female**. We therefore adjust our feature extractor to include features for two-letter\n","suffixes:\n"]},{"cell_type":"code","execution_count":null,"id":"290fad60","metadata":{"id":"290fad60","executionInfo":{"status":"aborted","timestamp":1712078216406,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["def gender_features(word):\n","    return {'suffix1': word[-1:],'suffix2': word[-2:]}\n"]},{"cell_type":"markdown","id":"f0c534cb","metadata":{"id":"f0c534cb"},"source":["**Rebuilding the classifier with the new feature extractor, we see that the performance on the dev-test dataset\n","improves by almost 2 percentage points (from 75.2% to 77.2%):**"]},{"cell_type":"code","execution_count":null,"id":"fe3e1eaa","metadata":{"id":"fe3e1eaa","executionInfo":{"status":"aborted","timestamp":1712078216406,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n","devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","print(nltk.classify.accuracy(classifier, devtest_set))"]},{"cell_type":"markdown","id":"c234d247","metadata":{"id":"c234d247"},"source":["This error analysis procedure can then be repeated, checking for patterns in the errors that are made by the\n","newly improved classifier. Each time the error analysis procedure is repeated, we should select a different\n","dev-test/training split, to ensure that the classifier does not start to reflect idiosyncrasies in the dev-test set.\n","But once we've used the dev-test set to help us develop the model, we can no longer trust that it will give us\n","an accurate idea of how well the model would perform on new data. It is therefore important to keep the test\n","set separate, and unused, until our model development is complete. At that point, we can use the test set to\n","evaluate how well our model will perform on new input values.\n"]},{"cell_type":"markdown","id":"a1d9e78f","metadata":{"id":"a1d9e78f"},"source":["# 1.3 Document Classification\n","\n","In 1, we saw several examples of corpora where documents have been labeled with categories. Using these\n","corpora, we can build classifiers that will automatically tag new documents with appropriate category labels.\n","\n","\n","First, we construct a list of documents, labeled with the appropriate categories. For this example, we've\n","chosen the Movie Reviews Corpus, which categorizes each review as positive or negative."]},{"cell_type":"code","execution_count":null,"id":"03b20a9b","metadata":{"id":"03b20a9b","executionInfo":{"status":"aborted","timestamp":1712078216406,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["from nltk.corpus import movie_reviews\n","documents = [(list(movie_reviews.words(fileid)), category)\n","for category in movie_reviews.categories()\n","for fileid in movie_reviews.fileids(category)]\n","random.shuffle(documents)\n"]},{"cell_type":"markdown","id":"de0e74c4","metadata":{"id":"de0e74c4"},"source":["Next, we define a feature extractor for documents, so the classifier will know which aspects of the data it\n","should pay attention to (1.4). For document topic identification, we can define a feature for each word,\n","indicating whether the document contains that word. To limit the number of features that the classifier needs\n","to process, we begin by constructing a list of the 2000 most frequent words in the overall corpus . We can\n","then define a feature extractor that simply checks whether each of these words is present in a given\n","document.\n"]},{"cell_type":"code","execution_count":null,"id":"8dc9cb37","metadata":{"id":"8dc9cb37","executionInfo":{"status":"aborted","timestamp":1712078216406,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n","word_features = list(all_words)[:2000]\n","def document_features(document):\n","    document_words = set(document)\n","    features = {}\n","    for word in word_features:\n","        features['contains({})'.format(word)] = (word in document_words)\n","    return features"]},{"cell_type":"code","execution_count":null,"id":"bbbb129c","metadata":{"id":"bbbb129c","executionInfo":{"status":"aborted","timestamp":1712078216406,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":[" print(document_features(movie_reviews.words('pos/cv957_8737.txt')))"]},{"cell_type":"markdown","id":"09e4b623","metadata":{"id":"09e4b623"},"source":["Now that we've defined our feature extractor, we can use it to train a classifier to label new movie reviews\n","(1.5). To check how reliable the resulting classifier is, we compute its accuracy on the test set . And once\n","again, we can use show_most_informative_features() to find out which features the classifier found to be\n","most informative"]},{"cell_type":"code","execution_count":null,"id":"0005df75","metadata":{"id":"0005df75","executionInfo":{"status":"aborted","timestamp":1712078216407,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["featuresets = [(document_features(d), c) for (d,c) in documents]\n","train_set, test_set = featuresets[100:], featuresets[:100]\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","print(nltk.classify.accuracy(classifier, test_set))"]},{"cell_type":"code","execution_count":null,"id":"597a02d4","metadata":{"id":"597a02d4","executionInfo":{"status":"aborted","timestamp":1712078216407,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["classifier.show_most_informative_features(5)"]},{"cell_type":"markdown","id":"aff35a90","metadata":{"id":"aff35a90"},"source":["Apparently in this corpus, a review that mentions \"Seagal\" is almost 8 times more likely to be negative than\n","positive, while a review that mentions \"Damon\" is about 6 times more likely to be positive.\n"]},{"cell_type":"markdown","id":"29b6e8f3","metadata":{"id":"29b6e8f3"},"source":["# 1.4 Part-of-Speech Tagging\n","We\n","can train a classifier to work out which suffixes are most informative. Let's begin by finding out what the\n","most common suffixes are:"]},{"cell_type":"code","execution_count":null,"id":"dfd78b2c","metadata":{"id":"dfd78b2c","executionInfo":{"status":"aborted","timestamp":1712078216407,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["import nltk\n","from nltk.corpus import brown\n","suffix_fdist = nltk.FreqDist()\n","for word in brown.words():\n","    word = word.lower()\n","    suffix_fdist[word[-1:]] += 1\n","    suffix_fdist[word[-2:]] += 1\n","    suffix_fdist[word[-3:]] += 1"]},{"cell_type":"code","execution_count":null,"id":"4030c698","metadata":{"id":"4030c698","executionInfo":{"status":"aborted","timestamp":1712078216407,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n","print(common_suffixes)"]},{"cell_type":"markdown","id":"195c2609","metadata":{"id":"195c2609"},"source":["Next, we'll define a feature extractor function which checks a given word for these suffixes:\n"]},{"cell_type":"code","execution_count":null,"id":"4e02081d","metadata":{"id":"4e02081d","executionInfo":{"status":"aborted","timestamp":1712078216407,"user_tz":-330,"elapsed":32,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["def pos_features(word):\n","    features = {}\n","    for suffix in common_suffixes:\n","        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n","    return features"]},{"cell_type":"markdown","id":"7667d1ba","metadata":{"id":"7667d1ba"},"source":["Feature extraction functions behave like tinted glasses, highlighting some of the properties (colors) in our\n","data and making it impossible to see other properties. The classifier will rely exclusively on these highlighted\n","properties when determining how to label inputs. In this case, the classifier will make its decisions based only\n","on information about which of the common suffixes (if any) a given word has:"]},{"cell_type":"code","execution_count":null,"id":"a8cda9cf","metadata":{"id":"a8cda9cf","executionInfo":{"status":"aborted","timestamp":1712078216407,"user_tz":-330,"elapsed":32,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["tagged_words = brown.tagged_words(categories='news')\n","featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"]},{"cell_type":"code","execution_count":null,"id":"67b0d7b1","metadata":{"id":"67b0d7b1","executionInfo":{"status":"aborted","timestamp":1712078216408,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["classifier = nltk.DecisionTreeClassifier.train(train_set)\n","nltk.classify.accuracy(classifier, test_set)\n"]},{"cell_type":"code","execution_count":null,"id":"ca784225","metadata":{"id":"ca784225","executionInfo":{"status":"aborted","timestamp":1712078216408,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["classifier.classify(pos_features('good'))"]},{"cell_type":"markdown","id":"a33cea13","metadata":{"id":"a33cea13"},"source":["One nice feature of decision tree models is that they are often fairly easy to interpret — we can even instruct\n","NLTK to print them out as pseudocode:\n"]},{"cell_type":"code","execution_count":null,"id":"bdf97d85","metadata":{"id":"bdf97d85","executionInfo":{"status":"aborted","timestamp":1712078216408,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["print(classifier.pseudocode(depth=4))"]},{"cell_type":"markdown","id":"967a91b1","metadata":{"id":"967a91b1"},"source":["Here, we can see that the classifier begins by checking whether a word ends with a comma — if so, then it\n","will receive the special tag \",\". Next, the classifier checks if the word ends in \"the\", in which case it's almost\n","certainly a determiner. This \"suffix\" gets used early by the decision tree because the word \"the\" is so\n","common. Continuing on, the classifier checks if the word ends in \"s\". If so, then it's most likely to receive the\n","verb tag VBZ (unless it's the word \"is\", which has a special tag BEZ), and if not, then it's most likely a noun\n","(unless it's the punctuation mark \".\"). The actual classifier contains further nested if-then statements below\n","the ones shown here, but the depth=4 argument just displays the top portion of the decision tree.\n"]},{"cell_type":"markdown","id":"81d766b7","metadata":{"id":"81d766b7"},"source":["# 1.5 Exploiting Context\n","\n","By augmenting the feature extraction function, we could modify this part-of-speech tagger to leverage a\n","variety of other word-internal features, such as the **length of the word, the number of syllables it contains, or\n","its prefix**. However, as long as the feature extractor just looks at the target word, we have no way to add\n","features that depend on the context that the word appears in. But contextual features often provide powerful\n","clues about the correct tag — for example, when tagging the word \"fly,\" knowing that the previous word is\n","\"a\" will allow us to determine that it is functioning as a noun, not a verb.\n","In order to accommodate features that depend on a word's context, we must revise the pattern that we used to\n","define our feature extractor. Instead of just passing in the word to be tagged, we will pass in a complete\n","(untagged) sentence, along with the index of the target word. This approach is demonstrated in 1.6, which\n","employs a context-dependent feature extractor to define a part of speech tag classifier.\n"]},{"cell_type":"code","execution_count":null,"id":"6aa568cd","metadata":{"id":"6aa568cd","executionInfo":{"status":"aborted","timestamp":1712078216408,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["def pos_features(sentence, i):\n","    # Initialize an empty dictionary to store features\n","    features = {\n","        \"suffix(1)\": sentence[i][-1:],  # Last character of the word at index i\n","        \"suffix(2)\": sentence[i][-2:],  # Last two characters of the word at index i\n","        \"suffix(3)\": sentence[i][-3:]   # Last three characters of the word at index i\n","    }\n","\n","    # Check if the current word is the first word in the sentence\n","    if i == 0:\n","        features[\"prev-word\"] = \"<START>\"  # Special tag for the first word\n","    else:\n","        features[\"prev-word\"] = sentence[i - 1]  # Previous word in the sentence\n","\n","    # Return the generated features\n","    return features\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ecc4ea6f","metadata":{"id":"ecc4ea6f","executionInfo":{"status":"aborted","timestamp":1712078216408,"user_tz":-330,"elapsed":32,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["pos_features(brown.sents()[0], 8)\n","{'suffix(3)': 'ion', 'prev-word': 'an', 'suffix(2)': 'on', 'suffix(1)': 'n'}\n","tagged_sents = brown.tagged_sents(categories='news')\n","featuresets = []\n","for tagged_sent in tagged_sents:\n","    untagged_sent = nltk.tag.untag(tagged_sent)\n","    for i, (word, tag) in enumerate(tagged_sent):\n","        featuresets.append( (pos_features(untagged_sent, i), tag) )\n","        size = int(len(featuresets) * 0.1)\n","        train_set, test_set = featuresets[size:], featuresets[:size]\n","        classifier = nltk.NaiveBayesClassifier.train(train_set)\n","        nltk.classify.accuracy(classifier, test_set)\n"]},{"cell_type":"markdown","id":"2c04f788","metadata":{"id":"2c04f788"},"source":["**Detailed Explanation**\n","\n","The code is an implementation of a part-of-speech (POS) tagging model using the Brown Corpus from the Natural Language Toolkit (nltk) in Python. Let's break down the code step by step:\n","\n","1. **pos_features(brown.sents()[0], 8)**:\n","   - This calls the `pos_features` function with the first sentence (`brown.sents()[0]`) of the Brown Corpus and the index `8`. The resulting features for the word at index 8 are:\n","     - 'suffix(1)': 'n' (last character)\n","     - 'suffix(2)': 'on' (last two characters)\n","     - 'suffix(3)': 'ion' (last three characters)\n","     - 'prev-word': 'an' (previous word)\n","\n","2. **tagged_sents = brown.tagged_sents(categories='news')**:\n","   - This retrieves the tagged sentences from the Brown Corpus, specifically those in the 'news' category. Each sentence is a list of tuples where each tuple contains a word and its corresponding part-of-speech tag.\n","\n","3. **featuresets = []**:\n","   - Initializes an empty list to store feature sets.\n","\n","4. **for tagged_sent in tagged_sents:**\n","   - Iterates over each tagged sentence in the 'news' category.\n","\n","5. **untagged_sent = nltk.tag.untag(tagged_sent)**:\n","   - Removes the part-of-speech tags, leaving only a list of words from the current sentence.\n","\n","6. **for i, (word, tag) in enumerate(tagged_sent):**:\n","   - Iterates over each word-tag pair in the current tagged sentence.\n","\n","7. **featuresets.append((pos_features(untagged_sent, i), tag))**:\n","   - Calls `pos_features` to extract features for the word at index `i` in the untagged sentence and appends a tuple `(features, tag)` to the `featuresets` list.\n","\n","8. **size = int(len(featuresets) * 0.1)**:\n","   - Calculates 10% of the total number of feature sets.\n","\n","9. **train_set, test_set = featuresets[size:], featuresets[:size]**:\n","   - Splits the featuresets into training and testing sets.\n","\n","10. **classifier = nltk.NaiveBayesClassifier.train(train_set)**:\n","   - Trains a Naive Bayes classifier using the training set.\n","\n","11. **nltk.classify.accuracy(classifier, test_set)**:\n","   - Evaluates the accuracy of the trained classifier on the test set.\n","\n","Note: The indentation of the code appears to be incorrect, and the training and testing code should be outside the loop over the tagged sentences for proper execution. Also, make sure to fix the indentation to ensure that the classifier is trained and tested after all feature sets are generated."]},{"cell_type":"markdown","id":"d1d11b00","metadata":{"id":"d1d11b00"},"source":["It is clear that exploiting contextual features improves the performance of our part-of-speech tagger. For\n","example, the classifier learns that a word is likely to be a noun if it comes immediately after the word \"large\"\n","or the word \"gubernatorial\". However, it is unable to learn the generalization that a word is probably a noun\n","if it follows an adjective, because it doesn't have access to the previous word's part-of-speech tag. In general,\n","simple classifiers always treat each input as independent from all other inputs. In many contexts, this makes\n","perfect sense. For example, decisions about whether names tend to be male or female can be made on a case\u0002by-case basis. However, there are often cases, such as part-of-speech tagging, where we are interested in\n","solving classification problems that are closely related to one another.\n"]},{"cell_type":"markdown","id":"3d3b8a73","metadata":{"id":"3d3b8a73"},"source":["# 1.6 Sequence Classification\n","In order to capture the dependencies between related classification tasks, we can use joint classifier models,\n","which choose an appropriate labeling for a collection of related inputs. **In the case of part-of-speech tagging,\n","a variety of different sequence classifier models can be used to jointly choose part-of-speech tags for all the\n","words in a given sentence.\n","One sequence classification strategy, known as consecutive classification or greedy sequence classification,\n","is to find the most likely class label for the first input, then to use that answer to help find the best label for\n","the next input. The process can then be repeated until all of the inputs have been labeled.**"]},{"cell_type":"code","execution_count":null,"id":"ef7af314","metadata":{"id":"ef7af314","executionInfo":{"status":"aborted","timestamp":1712078216409,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["def pos_features(sentence, i, history):\n","    features = {\"suffix(1)\": sentence[i][-1:],\"suffix(2)\": sentence[i][-2:],\n","                \"suffix(3)\": sentence[i][-3:]}\n","    if i == 0:\n","        features[\"prev-word\"] = \"<START>\"\n","        features[\"prev-tag\"] = \"<START>\"\n","    else:\n","        features[\"prev-word\"] = sentence[i-1]\n","        features[\"prev-tag\"] = history[i-1]\n","    return features\n","\n","class ConsecutivePosTagger(nltk.TaggerI):\n","    def __init__(self, train_sents):\n","        train_set = []\n","        for tagged_sent in train_sents\n","        untagged_sent = nltk.tag.untag(tagged_sent)\n","        history = []\n","            for i, (word, tag) in enumerate(tagged_sent):\n","                featureset = pos_features(untagged_sent, i, history)\n","                train_set.append( (featureset, tag) )\n","                history.append(tag)\n","        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n","\n","    def tag(self, sentence):\n","        history = []\n","        for i, word in enumerate(sentence):\n","            featureset = pos_features(sentence, i, history)\n","            tag = self.classifier.classify(featureset)\n","            history.append(tag)\n","        return zip(sentence, history)\n","\n","tagged_sents = brown.tagged_sents(categories='news')\n","size = int(len(tagged_sents) * 0.1)\n","train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n","tagger = ConsecutivePosTagger(train_sents)\n","print(tagger.evaluate(test_sents))\n","\n"]},{"cell_type":"markdown","id":"464f41b6","metadata":{"id":"464f41b6"},"source":["**Detailed Explanation**\n","\n","The provided code defines a part-of-speech (POS) tagger using a consecutive approach, where the prediction of the current tag is influenced by the previous word's tag. This approach is often used for sequence labeling tasks like POS tagging. Let's break down the code:\n","\n","1. **pos_features function**:\n","   ```python\n","   def pos_features(sentence, i, history):\n","       features = {\n","           \"suffix(1)\": sentence[i][-1:],\n","           \"suffix(2)\": sentence[i][-2:],\n","           \"suffix(3)\": sentence[i][-3:]\n","       }\n","       if i == 0:\n","           features[\"prev-word\"] = \"<START>\"\n","           features[\"prev-tag\"] = \"<START>\"\n","       else:\n","           features[\"prev-word\"] = sentence[i-1]\n","           features[\"prev-tag\"] = history[i-1]\n","       return features\n","   ```\n","   - This function takes a sentence, an index `i`, and a history of tags as input.\n","   - It extracts features for the word at index `i` in the sentence, including the last three characters of the word, the previous word, and the previous tag.\n","   - If the word is the first word in the sentence, special tags `<START>` are used for both the previous word and tag.\n","\n","2. **ConsecutivePosTagger class**:\n","   ```python\n","   class ConsecutivePosTagger(nltk.TaggerI):\n","       def __init__(self, train_sents):\n","           train_set = []\n","           for tagged_sent in train_sents:\n","               untagged_sent = nltk.tag.untag(tagged_sent)\n","               history = []\n","               for i, (word, tag) in enumerate(tagged_sent):\n","                   featureset = pos_features(untagged_sent, i, history)\n","                   train_set.append((featureset, tag))\n","                   history.append(tag)\n","           self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n","       \n","       def tag(self, sentence):\n","           history = []\n","           for i, word in enumerate(sentence):\n","               featureset = pos_features(sentence, i, history)\n","               tag = self.classifier.classify(featureset)\n","               history.append(tag)\n","           return zip(sentence, history)\n","   ```\n","   - This class inherits from `nltk.TaggerI` and represents a consecutive POS tagger.\n","   - The `__init__` method trains the tagger using a training set. It iterates over tagged sentences, extracts features using `pos_features`, and builds a training set.\n","   - The `tag` method tags a given input sentence using the trained classifier. It maintains a history of predicted tags as it iterates through the words in the sentence.\n","\n","3. **Testing the tagger**:\n","   ```python\n","   tagged_sents = brown.tagged_sents(categories='news')\n","   size = int(len(tagged_sents) * 0.1)\n","   train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n","   tagger = ConsecutivePosTagger(train_sents)\n","   print(tagger.evaluate(test_sents))\n","   ```\n","   - It tests the tagger on a test set and prints the evaluation result.\n","\n","Note: The indentation within the `__init__` method is corrected in this response for better readability. Ensure proper indentation when using the code."]},{"cell_type":"markdown","id":"bbfc8607","metadata":{"id":"bbfc8607"},"source":["# 2 Further Examples of Supervised Classification\n","\n","**2.1 Sentence Segmentation**\n","\n","Sentence segmentation can be viewed as a classification task for punctuation: whenever we encounter a\n","symbol that could possibly end a sentence, such as a period or a question mark, we have to decide whether it\n","terminates the preceding sentence.\n","The first step is to obtain some data that has already been segmented into sentences and convert it into a form\n","that is suitable for extracting features:"]},{"cell_type":"code","execution_count":null,"id":"22818ca1","metadata":{"id":"22818ca1","executionInfo":{"status":"aborted","timestamp":1712078216409,"user_tz":-330,"elapsed":33,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["sents = nltk.corpus.treebank_raw.sents()\n","tokens = []\n","boundaries = set()\n","offset = 0\n","for sent in sents:\n","    tokens.extend(sent)\n","    offset += len(sent)\n","    boundaries.add(offset-1)"]},{"cell_type":"markdown","id":"c97a436d","metadata":{"id":"c97a436d"},"source":["**Detailed Explanation**\n","\n","The provided code processes sentences from the Treebank corpus in the Natural Language Toolkit (nltk). Let's break down the code step by step:\n","\n","```python\n","sents = nltk.corpus.treebank_raw.sents()\n","```\n","\n","This line retrieves the sentences from the Treebank corpus using `nltk.corpus.treebank_raw.sents()`. The variable `sents` now contains a list of sentences, where each sentence is represented as a list of words.\n","\n","```python\n","tokens = []\n","boundaries = set()\n","offset = 0\n","```\n","\n","These lines initialize three variables:\n","- `tokens`: An empty list to store individual words.\n","- `boundaries`: An empty set to store indices where sentence boundaries occur.\n","- `offset`: A variable to keep track of the cumulative length of sentences.\n","\n","```python\n","for sent in sents:\n","    tokens.extend(sent)\n","    offset += len(sent)\n","    boundaries.add(offset-1)\n","```\n","\n","This loop iterates through each sentence in `sents`:\n","- `tokens.extend(sent)`: It appends all the words from the current sentence to the `tokens` list, effectively concatenating all the sentences into a single list of words.\n","- `offset += len(sent)`: It updates the `offset` variable by adding the length of the current sentence. This keeps track of the cumulative length of all the sentences processed so far.\n","- `boundaries.add(offset-1)`: It adds the current offset (minus 1) to the `boundaries` set. The subtraction of 1 is likely done to represent the index of the last word in each sentence, serving as a boundary marker.\n","\n","After this loop, `tokens` contains all the words from the sentences concatenated into a single list, and `boundaries` contains indices that mark the boundaries between sentences.\n","\n","In summary, this code snippet is a pre-processing step that processes sentences from the Treebank corpus, concatenates all the words into a single list (`tokens`), and identifies boundaries between sentences using the `boundaries` set."]},{"cell_type":"markdown","id":"5800452c","metadata":{"id":"5800452c"},"source":["Here, tokens is a merged list of tokens from the individual sentences, and boundaries is a set containing the\n","indexes of all sentence-boundary tokens. Next, we need to specify the features of the data that will be used in\n","order to decide whether punctuation indicates a sentence-boundary:\n"]},{"cell_type":"code","execution_count":null,"id":"270812ff","metadata":{"id":"270812ff","executionInfo":{"status":"aborted","timestamp":1712078216410,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["def punct_features(tokens, i):\n","    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n","            'prev-word': tokens[i-1].lower(),\n","            'punct': tokens[i],\n","            'prev-word-is-one-char': len(tokens[i-1]) == 1}\n"]},{"cell_type":"markdown","id":"c94f30b8","metadata":{"id":"c94f30b8"},"source":["Based on this feature extractor, we can create a list of labeled featuresets by selecting all the punctuation\n","tokens, and tagging whether they are boundary tokens or not:\n"]},{"cell_type":"code","execution_count":null,"id":"b23377cc","metadata":{"id":"b23377cc","executionInfo":{"status":"aborted","timestamp":1712078216411,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["featuresets = [(punct_features(tokens, i), (i in boundaries))\n","               for i in range(1, len(tokens)-1)\n","               if tokens[i] in '.?!']\n"]},{"cell_type":"markdown","id":"e789d1d6","metadata":{"id":"e789d1d6"},"source":["Using these feature sets, we can train and evaluate a punctuation classifier:\n"]},{"cell_type":"code","execution_count":null,"id":"16f408be","metadata":{"id":"16f408be","executionInfo":{"status":"aborted","timestamp":1712078216411,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["size = int(len(featuresets) * 0.1)\n","train_set, test_set = featuresets[size:], featuresets[:size]\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","nltk.classify.accuracy(classifier, test_set)"]},{"cell_type":"markdown","id":"6cd7438d","metadata":{"id":"6cd7438d"},"source":["To use this classifier to perform sentence segmentation, we simply check each punctuation mark to see\n","whether it's labeled as a boundary; and divide the list of words at the boundary marks. The listing below\n","shows how this can be done."]},{"cell_type":"code","execution_count":null,"id":"8a1ff174","metadata":{"id":"8a1ff174","executionInfo":{"status":"aborted","timestamp":1712078216411,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["def segment_sentences(words):\n","    start = 0\n","    sents = []\n","    for i, word in enumerate(words):\n","        if word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n","            sents.append(words[start:i+1])\n","            start = i+1\n","    if start < len(words):\n","        sents.append(words[start:])\n","    return sents\n"]},{"cell_type":"markdown","id":"b9eb398e","metadata":{"id":"b9eb398e"},"source":["# 2.2 Identifying Dialogue Act Types\n","\n","When processing dialogue, it can be useful to think of utterances as a type of action performed by the\n","speaker. This interpretation is most straightforward for performative statements such as \"I forgive you\" or \"I\n","bet you can't climb that hill.\" But greetings, questions, answers, assertions, and clarifications can all be\n","thought of as types of speech-based actions. Recognizing the dialogue acts underlying the utterances in a\n","dialogue can be an important first step in understanding the conversation.\n","\n","\n","The NPS Chat Corpus, which was demonstrated in 1, consists of over 10,000 posts from instant messaging\n","sessions. These posts have all been labeled with one of 15 dialogue act types, such as \"Statement,\"\n","\"Emotion,\" \"ynQuestion\", and \"Continuer.\" We can therefore use this data to build a classifier that can\n","identify the dialogue act types for new instant messaging posts. The first step is to extract the basic\n","messaging data. We will call xml_posts() to get a data structure representing the XML annotation for each\n","post:"]},{"cell_type":"code","execution_count":null,"id":"f055e55a","metadata":{"id":"f055e55a","executionInfo":{"status":"aborted","timestamp":1712078216411,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["import nltk\n","posts = nltk.corpus.nps_chat.xml_posts()[:10000]\n"]},{"cell_type":"markdown","id":"c9176df7","metadata":{"id":"c9176df7"},"source":["**Detailed Explanation**\n","\n","posts = nltk.corpus.nps_chat.xml_posts()[:10000]\n","\n","This line retrieves a subset of posts from the NPS Chat Corpus. Here's a breakdown of each part:\n","\n","- `nltk.corpus.nps_chat`: This accesses the NPS Chat Corpus included in the NLTK library. The NPS Chat Corpus contains instant messaging chats.\n","\n","- `.xml_posts()`: This method specifically retrieves the posts from the corpus. Each post typically represents a single message in a chat.\n","\n","- `[:10000]`: This slice notation is used to select the first 10,000 posts from the NPS Chat Corpus. It limits the number of posts to the first 10,000 in the dataset.\n","\n","After running this code, the variable `posts` will contain a list of XML posts from the NPS Chat Corpus. Each post is likely to have attributes such as the content of the message, the user who posted it, and other relevant information. This subset of posts (the first 10,000) can be used for various natural language processing tasks, such as text analysis, sentiment analysis, or any other application that involves analyzing chat messages."]},{"cell_type":"markdown","id":"a31ae7a9","metadata":{"id":"a31ae7a9"},"source":["Next, we'll define a simple feature extractor that checks what words the post contains:\n"]},{"cell_type":"code","execution_count":null,"id":"e62c119a","metadata":{"id":"e62c119a","executionInfo":{"status":"aborted","timestamp":1712078216411,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["import nltk\n","\n","def dialogue_act_features(post):\n","    features = {}\n","    for word in nltk.word_tokenize(post):\n","        features['contains({})'.format(word.lower())] = True\n","    return features\n"]},{"cell_type":"markdown","id":"3b1f3b29","metadata":{"id":"3b1f3b29"},"source":["**Detailed Explanation**\n","\n","This code defines a function called `dialogue_act_features` that extracts features from a given text post for the purpose of dialogue act classification. Dialogue act classification involves categorizing a piece of text (e.g., a sentence or message) based on the type of discourse act it represents, such as a question, statement, request, etc.\n","\n","Let's break down the function:\n","\n","```python\n","import nltk\n","```\n","This line imports the Natural Language Toolkit (NLTK) library, which is widely used for natural language processing tasks in Python.\n","\n","```python\n","def dialogue_act_features(post):\n","    features = {}\n","    for word in nltk.word_tokenize(post):\n","        features['contains({})'.format(word.lower())] = True\n","    return features\n","```\n","- **`def dialogue_act_features(post):`**: This line defines the `dialogue_act_features` function, which takes a single argument `post` representing a text post.\n","\n","- **`features = {}`**: Initializes an empty dictionary called `features` to store the extracted features.\n","\n","- **`for word in nltk.word_tokenize(post):`**: This line tokenizes the input `post` into words using NLTK's `word_tokenize` function, and then iterates through each word.\n","\n","- **`features['contains({})'.format(word.lower())] = True`**: For each word in the tokenized post, it creates a feature key in the `features` dictionary using the format `'contains({})'.format(word.lower())`. This format represents whether the word is present in the post, and it converts the word to lowercase for case-insensitive matching. The value associated with each feature is set to `True`.\n","\n","- **`return features`**: After iterating through all words in the post, the function returns the dictionary of features.\n","\n","The purpose of this function is to generate a simple bag-of-words representation of the input text post. Each word in the post becomes a feature, and the feature value is set to `True` if the word is present. This type of feature extraction is often used as a basic representation for text classification tasks, including dialogue act classification. The resulting features can be used as input to a machine learning model to train a classifier for predicting dialogue acts based on the words present in a text post."]},{"cell_type":"markdown","id":"0266f3b9","metadata":{"id":"0266f3b9"},"source":["Finally, we construct the training and testing data by applying the feature extractor to each post (using\n","post.get('class') to get a post's dialogue act type), and create a new classifier:"]},{"cell_type":"code","execution_count":null,"id":"b1505a19","metadata":{"id":"b1505a19","executionInfo":{"status":"aborted","timestamp":1712078216411,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["featuresets = [(dialogue_act_features(post.text), post.get('class'))\n","for post in posts]\n","size = int(len(featuresets) * 0.1)\n","train_set, test_set = featuresets[size:], featuresets[:size]\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","print(nltk.classify.accuracy(classifier, test_set))"]},{"cell_type":"markdown","id":"d64c3cea","metadata":{"id":"d64c3cea"},"source":["# 3 Evaluation\n","\n","In order to decide whether a classification model is accurately capturing a pattern, we must evaluate that\n","model. The result of this evaluation is important for deciding how trustworthy the model is, and for what\n","purposes we can use it. Evaluation can also be an effective tool for guiding us in making future\n","improvements to the model."]},{"cell_type":"markdown","id":"e86501c3","metadata":{"id":"e86501c3"},"source":["# 3.1 The Test Set\n","\n","Most evaluation techniques calculate a score for a model by comparing the labels that it generates for the\n","inputs in a test set (or evaluation set) with the correct labels for those inputs. This test set typically has the\n","same format as the training set. However, it is very important that the test set be distinct from the training\n","corpus: if we simply re-used the training set as the test set, then a model that simply memorized its input,\n","without learning how to generalize to new examples, would receive misleadingly high scores.\n","\n","When building the test set, there is often a trade-off between the amount of data available for testing and the\n","amount available for training. For classification tasks that have a small number of well-balanced labels and a\n","diverse test set, a meaningful evaluation can be performed with as few as 100 evaluation instances. But if a\n","classification task has a large number of labels, or includes very infrequent labels, then the size of the test set\n","should be chosen to ensure that the least frequent label occurs at least 50 times. Additionally, if the test set\n","contains many closely related instances — such as instances drawn from a single document — then the size\n","of the test set should be increased to ensure that this lack of diversity does not skew the evaluation results.\n","When large amounts of annotated data are available, it is common to err on the side of safety by using 10%\n","of the overall data for evaluation.\n","\n","Another consideration when choosing the test set is the degree of similarity between instances in the test set\n","and those in the development set. The more similar these two datasets are, the less confident we can be that\n","evaluation results will generalize to other datasets. For example, consider the part-of-speech tagging task. At\n","one extreme, we could create the training set and test set by randomly assigning sentences from a data source\n","that reflects a single genre (news):"]},{"cell_type":"code","execution_count":null,"id":"38155823","metadata":{"id":"38155823","executionInfo":{"status":"aborted","timestamp":1712078216412,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["import random\n","from nltk.corpus import brown\n","tagged_sents = list(brown.tagged_sents(categories='news'))\n","random.shuffle(tagged_sents)\n","size = int(len(tagged_sents) * 0.1)\n","train_set, test_set = tagged_sents[size:], tagged_sents[:size]"]},{"cell_type":"markdown","id":"fa338907","metadata":{"id":"fa338907"},"source":["In this case, our test set will be very similar to our training set. The training set and test set are taken from the\n","same genre, and so we cannot be confident that evaluation results would generalize to other genres. What's\n","worse, because of the call to random.shuffle(), the test set contains sentences that are taken from the same\n","documents that were used for training. If there is any consistent pattern within a document — say, if a given\n","word appears with a particular part-of-speech tag especially frequently — then that difference will be\n","reflected in both the development set and the test set. A somewhat better approach is to ensure that the\n","training set and test set are taken from different documents:\n","In this case, our test set will be very similar to our training set. The training set and test set are taken from the\n","same genre, and so we cannot be confident that evaluation results would generalize to other genres. What's\n","worse, because of the call to random.shuffle(), the test set contains sentences that are taken from the same\n","documents that were used for training. If there is any consistent pattern within a document — say, if a given\n","word appears with a particular part-of-speech tag especially frequently — then that difference will be\n","reflected in both the development set and the test set. A somewhat better approach is to ensure that the\n","training set and test set are taken from different documents:\n"]},{"cell_type":"code","execution_count":null,"id":"99c6952f","metadata":{"id":"99c6952f","executionInfo":{"status":"aborted","timestamp":1712078216412,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["file_ids = brown.fileids(categories='news')\n","size = int(len(file_ids) * 0.1)\n","train_set = brown.tagged_sents(file_ids[size:])\n","test_set = brown.tagged_sents(file_ids[:size])\n"]},{"cell_type":"markdown","id":"38f15424","metadata":{"id":"38f15424"},"source":["If we want to perform a more stringent evaluation, we can draw the test set from documents that are less\n","closely related to those in the training set:"]},{"cell_type":"code","execution_count":null,"id":"cb5de525","metadata":{"id":"cb5de525","executionInfo":{"status":"aborted","timestamp":1712078216412,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["train_set = brown.tagged_sents(categories='news')\n","test_set = brown.tagged_sents(categories='fiction')\n"]},{"cell_type":"markdown","id":"f2e6da0b","metadata":{"id":"f2e6da0b"},"source":["If we build a classifier that performs well on this test set, then we can be confident that it has the power to\n","generalize well beyond the data that it was trained on.\n"]},{"cell_type":"markdown","id":"3ec74ed8","metadata":{"id":"3ec74ed8"},"source":["# 3.2 Accuracy\n","\n","The simplest metric that can be used to evaluate a classifier, accuracy, measures the percentage of inputs in\n","the test set that the classifier correctly labeled. For example, a name gender classifier that predicts the correct\n","name 60 times in a test set containing 80 names would have an accuracy of 60/80 = 75%. The function\n","nltk.classify.accuracy() will calculate the accuracy of a classifier model on a given test set:\n"]},{"cell_type":"code","execution_count":null,"id":"af9ab1c4","metadata":{"id":"af9ab1c4","executionInfo":{"status":"aborted","timestamp":1712078216412,"user_tz":-330,"elapsed":35,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}}},"outputs":[],"source":["import nltk\n","\n","# Example features (replace this with your actual feature extraction logic)\n","def extract_features(sentence):\n","    return {'contains_word': 'word' in sentence.lower()}\n","\n","# Example dataset\n","train_set = [({'contains_word': True}, 'positive'), ({'contains_word': False}, 'negative')]\n","test_set = [({'contains_word': True}, 'positive'), ({'contains_word': False}, 'negative')]\n","\n","# Training the Naive Bayes classifier\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","\n","# Evaluating and printing the accuracy\n","accuracy = nltk.classify.accuracy(classifier, test_set)\n","print('Accuracy: {:4.2f}'.format(accuracy))\n","\n"]},{"cell_type":"markdown","id":"2d2efb6e","metadata":{"id":"2d2efb6e"},"source":["Note:\n","When interpreting the accuracy score of a classifier, it is important to take into consideration the frequencies of the individual class labels in the test set."]},{"cell_type":"markdown","id":"62c05427","metadata":{"id":"62c05427"},"source":["# 3.3 Precision and Recall\n","\n","Another instance where accuracy scores can be misleading is in \"search\" tasks, such as information retrieval,\n","where we are attempting to find documents that are relevant to a particular task. Since the number of\n","irrelevant documents far outweighs the number of relevant documents, the accuracy score for a model that\n","labels every document as irrelevant would be very close to 100%.\n","\n","![prec.png](attachment:prec.png)"]},{"cell_type":"markdown","id":"eb8617ca","metadata":{"id":"eb8617ca"},"source":["It is therefore conventional to employ a different set of measures for search tasks, based on the number of\n","items in each of the four categories shown in 3.1:\n","    \n","True positives are relevant items that we correctly identified as relevant.\n","\n","True negatives are irrelevant items that we correctly identified as irrelevant.\n","\n","False positives (or Type I errors) are irrelevant items that we incorrectly identified as relevant.\n","\n","False negatives (or Type II errors) are relevant items that we incorrectly identified as irrelevant.\n","\n","Given these four numbers, we can define the following metrics:\n","    \n","Precision, which indicates how many of the items that we identified were relevant, is TP/(TP+FP).\n","\n","Recall, which indicates how many of the relevant items that we identified, is TP/(TP+FN).\n","\n","The F-Measure (or F-Score), which combines the precision and recall to give a single score, is\n","defined to be the harmonic mean of the precision and recall: (2 × Precision × Recall) / (Precision +\n","Recall).\n"]},{"cell_type":"markdown","id":"83605c90","metadata":{"id":"83605c90"},"source":["# 3.4 Confusion Matrices\n","\n","When performing classification tasks with three or more labels, it can be informative to subdivide the errors\n","made by the model based on which types of mistake it made. A confusion matrix is a table where each cell\n","[i,j] indicates how often label j was predicted when the correct label was i. Thus, the diagonal entries (i.e.,\n","cells |ii|) indicate labels that were correctly predicted, and the off-diagonal entries indicate errors."]},{"cell_type":"code","execution_count":4,"id":"72e03598","metadata":{"id":"72e03598","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1712080784826,"user_tz":-330,"elapsed":529,"user":{"displayName":"Dr. Padmaja S","userId":"04296087360295658892"}},"outputId":"d34744d5-9ba5-4eb1-86c4-0de8896761c3"},"outputs":[{"output_type":"error","ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mbrown\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('brown')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/brown\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mbrown\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('brown')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/brown.zip/brown/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-502fe639de3d>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Training a UnigramTagger using the Brown Corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbrown_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrown_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'editorial'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# or choose a suitable category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnigramTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mbrown\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('brown')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/brown\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"]}],"source":["import nltk\n","\n","def tag_list(tagged_sents):\n","    return [tag for sent in tagged_sents for (word, tag) in sent]\n","\n","def apply_tagger(tagger, corpus):\n","    return [tagger.tag(nltk.tag.untag(sent)) for sent in corpus]\n","\n","# Training a UnigramTagger using the Brown Corpus\n","brown_corpus = nltk.corpus.brown\n","train_sents = brown_corpus.tagged_sents(categories='editorial')  # or choose a suitable category\n","t2 = nltk.UnigramTagger(train_sents)\n","\n","gold = tag_list(brown_corpus.tagged_sents(categories='editorial'))\n","test = tag_list(apply_tagger(t2, brown_corpus.tagged_sents(categories='editorial')))\n","\n","cm = nltk.ConfusionMatrix(gold, test)\n","print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))\n","\n"]},{"cell_type":"markdown","id":"604e0c2c","metadata":{"id":"604e0c2c"},"source":["The confusion matrix indicates that common errors include a substitution of NN for JJ (for 1.6% of words),\n","and of NN for NNS (for 1.5% of words). Note that periods (.) indicate cells whose value is 0, and that the\n","diagonal entries — which correspond to correct classifications — are marked with angle brackets. .. XXX\n","explain use of \"reference\" in the legend above.\n"]},{"cell_type":"markdown","id":"b621f2b3","metadata":{"id":"b621f2b3"},"source":["# 3.5 Cross-Validation\n","\n","In order to evaluate our models, we must reserve a portion of the annotated data for the test set. As we\n","already mentioned, if the test set is too small, then our evaluation may not be accurate. However, making the\n","test set larger usually means making the training set smaller, which can have a significant impact on\n","performance if a limited amount of annotated data is available.\n","\n","One solution to this problem is to perform multiple evaluations on different test sets, then to combine the\n","scores from those evaluations, a technique known as cross-validation. In particular, we subdivide the\n","original corpus into N subsets called folds. For each of these folds, we train a model using all of the data\n","except the data in that fold, and then test that model on the fold. Even though the individual folds might be\n","too small to give accurate evaluation scores on their own, the combined evaluation score is based on a large\n","amount of data, and is therefore quite reliable.\n","\n","A second, and equally important, advantage of using cross-validation is that it allows us to examine how\n","widely the performance varies across different training sets. If we get very similar scores for all N training\n","sets, then we can be fairly confident that the score is accurate. On the other hand, if scores vary widely across\n","the N training sets, then we should probably be skeptical about the accuracy of the evaluation score.\n"]},{"cell_type":"markdown","id":"39bfcbde","metadata":{"id":"39bfcbde"},"source":["# 4. Naive Bayes Classifiers\n","\n","In naive Bayes classifiers, every feature gets a say in determining which label should be assigned to a given\n","input value. To choose a label for an input value, the naive Bayes classifier begins by calculating the prior\n","probability of each label, which is determined by checking frequency of each label in the training set. The\n","contribution from each feature is then combined with this prior probability, to arrive at a likelihood estimate\n","for each label. The label whose likelihood estimate is the highest is then assigned to the input value.\n","\n","![NB.png](attachment:NB.png)\n","\n"]},{"cell_type":"markdown","id":"126304a1","metadata":{"id":"126304a1"},"source":["NOTE:\n","\n","An abstract illustration of the procedure used by the naive Bayes classifier to choose the\n","topic for a document. In the training corpus, most documents are automotive, so the classifier starts out\n","at a point closer to the \"automotive\" label. But it then considers the effect of each feature. In this\n","example, the input document contains the word \"dark,\" which is a weak indicator for murder mysteries,\n","but it also contains the word \"football,\" which is a strong indicator for sports documents. After every\n","feature has made its contribution, the classifier checks which label it is closest to, and assigns that label\n","to the input."]},{"cell_type":"markdown","id":"2242756d","metadata":{"id":"2242756d"},"source":["Individual features make their contribution to the overall decision by \"voting against\" labels that don't occur\n","with that feature very often. In particular, the likelihood score for each label is reduced by multiplying it by\n","the probability that an input value with that label would have the feature. For example, if the word run occurs\n","in 12% of the sports documents, 10% of the murder mystery documents, and 2% of the automotive\n","\n","\n","documents, then the likelihood score for the sports label will be multiplied by 0.12; the likelihood score for\n","the murder mystery label will be multiplied by 0.1, and the likelihood score for the automotive label will be\n","multiplied by 0.02. The overall effect will be to reduce the score of the murder mystery label slightly more\n","than the score of the sports label, and to significantly reduce the automotive label with respect to the other\n","two labels. This process is illustrated below:\n","    \n","    "]},{"cell_type":"markdown","id":"63e25d04","metadata":{"id":"63e25d04"},"source":["![NB2.png](attachment:NB2.png)\n","\n","Calculating label likelihoods with naive Bayes. Naive Bayes begins by calculating the prior\n","probability of each label, based on how frequently each label occurs in the training data. Every feature\n","then contributes to the likelihood estimate for each label, by multiplying it by the probability that input\n","values with that label will have that feature. The resulting likelihood score can be thought of as an\n","estimate of the probability that a randomly selected value from the training set would have both the\n","given label and the set of features, assuming that the feature probabilities are all independent."]},{"cell_type":"markdown","id":"11d7ee1b","metadata":{"id":"11d7ee1b"},"source":["\n","Another way of understanding the naive Bayes classifier is that it chooses the most likely label for an input,\n","under the assumption that every input value is generated by first choosing a class label for that input value,\n","and then generating each feature, entirely independent of every other feature. Of course, this assumption is\n","unrealistic; features are often highly dependent on one another. We'll return to some of the consequences of\n","this assumption at the end of this section. This simplifying assumption, known as the naive Bayes\n","assumption (or independence assumption) makes it much easier to combine the contributions of the\n","different features, since we don't need to worry about how they should interact with one another.\n","\n","![NB%20classifier.png](attachment:NB%20classifier.png)"]},{"cell_type":"markdown","id":"22d7ba5e","metadata":{"id":"22d7ba5e"},"source":["As depicted in the above diagram, A Bayesian Network Graph illustrating the generative process that is assumed by the naive\n","Bayes classifier. To generate a labeled input, the model first chooses a label for the input, then it\n","generates each of the input's features based on that label. Every feature is assumed to be entirely\n","independent of every other feature, given the label.\n"]},{"cell_type":"markdown","id":"1d9dd797","metadata":{"id":"1d9dd797"},"source":["# Underlying Probabilistic Model\n","\n","\n","Based on this assumption, we can calculate an expression for P(label|features), the probability that an input\n","will have a particular label given that it has a particular set of features. To choose a label for a new input, we\n","can then simply pick the label l that maximizes P(l|features).\n","\n","To begin, we note that P(label|features) is equal to the probability that an input has a particular label and the\n","specified set of features, divided by the probability that it has the specified set of features:\n","    \n","(2) P(label|features) = P(features, label)/P(features)\n","\n","Next, we note that P(features) will be the same for every choice of label, so if we are simply interested in\n","finding the most likely label, it suffices to calculate P(features, label), which we'll call the label likelihood.\n","\n","Note\n","If we want to generate a probability estimate for each label, rather than just choosing the\n","most likely label, then the easiest way to compute P(features) is to simply calculate the sum\n","over labels of P(features, label):\n","(3) P(features) = Σl in| labels P(features, label)\n","\n","\n","The label likelihood can be expanded out as the probability of the label times the probability of the features\n","given the label:\n","(4) P(features, label) = P(label) × P(features|label)\n","\n","Furthermore, since the features are all independent of one another (given the label), we can separate out the\n","probability of each individual feature:\n","\n","(5) P(features, label) = P(label) × Prodf in| featuresP(f|label)`\n","\n","This is exactly the equation we discussed above for calculating the label likelihood: P(label) is the prior\n","probability for a given label, and each P(f|label) is the contribution of a single feature to the label likelihood.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}