
{"cells":[{"cell_type":"markdown","id":"9c0a154f","metadata":{"id":"9c0a154f"},"source":["# 1 Information Extraction\n","\n","Information comes in many shapes and sizes. One important form is structured data, where there is a regular and predictable\n","organization of entities and relationships. For example, we might be interested in the relation between companies and locations. Given a particular company, we would like to be able to identify the locations where it does business; conversely, given a location, we would like to discover which companies do business in that location. If our data is in tabular form, such as the example table asgiven below, then answering these queries is straightforward.\n","\n","![1.png](attachment:1.png)\n","\n","\n","If this location data was stored in Python as a list of tuples (entity, relation, entity), then the question \"Which organizations operate in Atlanta?\" could be translated as follows:"]},{"cell_type":"code","execution_count":null,"id":"ff3ef63b","metadata":{"id":"ff3ef63b","outputId":"c2e25df8-7acb-4843-d3a6-3c966ba11441"},"outputs":[{"name":"stdout","output_type":"stream","text":["['BBDO South', 'Georgia-Pacific']\n"]}],"source":[" locs = [('Omnicom', 'IN', 'New York'),\n","('DDB Needham', 'IN', 'New York'),\n","('Kaplan Thaler Group', 'IN', 'New York'),\n","('BBDO South', 'IN', 'Atlanta'),\n","('Georgia-Pacific', 'IN', 'Atlanta')]\n","query = [e1 for (e1, rel, e2) in locs if e2=='Atlanta']\n","print(query)\n"]},{"cell_type":"markdown","id":"7582b7cb","metadata":{"id":"7582b7cb"},"source":["we first convert the unstructured data of natural language sentences into the structured data. Then we reap the benefits of powerful query tools such as SQL. This\n","method of getting meaning from text is called Information Extraction.\n","\n","Application of Information Extraction\n","\n","It has many applications, including business intelligence, resume harvesting, media analysis, sentiment detection,\n","patent search, and email scanning. A particularly important area of current research involves the attempt to extract structured data out of\n","electronically-available scientific literature, especially in the domain of biology and medicine.\n"]},{"cell_type":"markdown","id":"e978776d","metadata":{"id":"e978776d"},"source":["# 1.1 Information Extraction Architecture\n","\n","shows the architecture for a simple information extraction system. It begins by processing a document using several of the\n","procedures discussed in 3 and 5.: first, the raw text of the document is split into sentences using a sentence segmenter, and each sentence is further subdivided into words using a tokenizer. Next, each sentence is tagged with part-of-speech tags, which will prove very helpful in the next step, named entity detection. In this step, we search for mentions of potentially interesting entities in each sentence. Finally, we use relation detection to search for likely relations between different entities in the text.\n","\n","![2.png](attachment:2.png)\n","\n","To perform the first three tasks, we can define a simple function that simply connects together NLTK's default sentence segmenter, word tokenizer, and part-of-speech tagger :\n","\n"]},{"cell_type":"code","execution_count":1,"id":"f55774e8","metadata":{"id":"f55774e8","executionInfo":{"status":"ok","timestamp":1706799348163,"user_tz":-330,"elapsed":1919,"user":{"displayName":"Maleeha Naaz","userId":"08100526136894511872"}}},"outputs":[],"source":["import nltk, re, pprint\n","def ie_preprocess(document):\n","    sentences = nltk.sent_tokenize(document)\n","    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n","    sentences = [nltk.pos_tag(sent) for sent in sentences]\n","    sentences.draw()\n"]},{"cell_type":"code","source":["ie_preprocess()"],"metadata":{"id":"eBsEHhiZK0Xy"},"id":"eBsEHhiZK0Xy","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"9ea7adb4","metadata":{"id":"9ea7adb4"},"source":["# 2 Chunking\n","The basic technique we will use for entity detection is chunking, which segments and labels multi-token sequences as shown below:\n","\n","The smaller boxes show the word-level tokenization and part-of-speech tagging, while the large boxes show higher-level chunking.\n","Each of these larger boxes is called a chunk. Like tokenization, which omits whitespace, chunking usually selects a subset of the tokens.\n","\n","![image.png](attachment:image.png)\n","\n","\n"]},{"cell_type":"markdown","id":"ce6129a7","metadata":{"id":"ce6129a7"},"source":["# 2.1 Noun Phrase Chunking\n","\n","Example of a Simple Regular Expression Based NP Chunker.\n","\n","In order to create an NP-chunker, we will first define a chunk grammar, consisting of rules that indicate how\n","sentences should be chunked. In this case, we will define a simple grammar with a single regular-expression rule . This rule says that an NP chunk should be formed whenever the chunker finds an optional determiner (DT) followed by any number of adjectives (JJ) and then a noun (NN). Using this grammar, we create a chunk parser, and test it on our example sentence . The result is a tree, which we can either print, or display graphically.\n","\n","![3.png](attachment:3.png)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"e85dd841","metadata":{"id":"e85dd841","outputId":"4c4918c7-0233-4934-a445-c03e49fbf9a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  (NP the/DT little/JJ yellow/JJ dog/NN)\n","  barked/VBD\n","  at/IN\n","  (NP the/DT cat/NN))\n"]}],"source":["import nltk\n","sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\n","(\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")]\n","grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n","cp = nltk.RegexpParser(grammar)\n","result = cp.parse(sentence)\n","print(result)\n","result.draw()"]},{"cell_type":"markdown","id":"6ee1693b","metadata":{"id":"6ee1693b"},"source":["# 2.2 Chinking\n","Sometimes it is easier to define what we want to exclude from a chunk. We can define a chink to be a sequence of tokens that is not\n","included in a chunk. In the following example, barked/VBD at/IN is a chink:\n","\n","[ the/DT little/JJ yellow/JJ dog/NN ] barked/VBD at/IN [ the/DT cat/NN ]\n","\n","Chinking is the process of removing a sequence of tokens from a chunk. If the matching sequence of tokens spans an entire chunk, then the whole chunk is removed; if the sequence of tokens appears in the middle of the chunk, these tokens are removed, leaving two\n","chunks where there was only one before. If the sequence is at the periphery of the chunk, these tokens are removed, and a smaller chunk\n","remains. These three possibilities are illustrated below:\n","\n"]},{"cell_type":"code","execution_count":null,"id":"1ef9ea71","metadata":{"id":"1ef9ea71","outputId":"0048f8e3-b35d-47e8-90e1-6544c57e300e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  (NP the/DT little/JJ yellow/JJ dog/NN)\n","  barked/VBD\n","  at/IN\n","  (NP the/DT cat/NN))\n"]}],"source":["grammar = r\"\"\"\n"," NP:\n"," {<.*>+} # Chunk everything\n"," }<VBD|IN>+{ # Chink sequences of VBD and IN\n"," \"\"\"\n","sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\n"," (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")]\n","cp = nltk.RegexpParser(grammar)\n","print(cp.parse(sentence))\n"]},{"cell_type":"markdown","id":"2cd94bc3","metadata":{"id":"2cd94bc3"},"source":["# 3 Developing and Evaluating Chunkers\n","\n","**The IOB format (short for inside, outside, beginning):**\n","\n","Commonly referred to as the BIO format, is a common tagging format for tagging tokens in a chunking task in computational linguistics (ex. named-entity recognition).\n","\n","The I- prefix before a tag indicates that the tag is inside a chunk. An O tag indicates that a token belongs to no chunk. The B- prefix before a tag indicates that the tag is the beginning of a chunk that immediately follows another chunk without O tags between them. It is used only in that case: when a chunk comes after an O tag, the first token of the chunk takes the I- prefix.\n","\n","An example with IOB format:\n","\n","Alex I-PER\n","is O\n","going O\n","to O\n","Los I-LOC\n","Angeles I-LOC\n","in O\n","California I-LOC\n","\n","Let us understand how to evaluate chunkers. As usual, this requires a suitably\n","annotated corpus. We begin\n","\n","1) by looking at the mechanics of converting IOB format into an NLTK tree,\n","2) at how this is done on a larger scale using a chunked corpus.\n","3) We will see how to score the accuracy of a chunker relative to a corpus\n","\n","\n","**We can use the NLTK corpus module to access a larger amount of chunked text. The CoNLL 2000 corpus contains 270k words of Wall\n","Street Journal text, divided into \"train\" and \"test\" portions, annotated with part-of-speech tags and chunk tags in the IOB format.**\n","\n","We can access the data using nltk.corpus.conll2000. Here is an example that reads the 100th sentence of the \"train\" portion of the corpus:\n","\n","![5.png](attachment:5.png)"]},{"cell_type":"code","execution_count":null,"id":"9f8db601","metadata":{"id":"9f8db601"},"outputs":[],"source":["from nltk.corpus import conll2000\n","print(conll2000.chunked_sents('train.txt')[99])\n"]},{"cell_type":"markdown","id":"8aa580ed","metadata":{"id":"8aa580ed"},"source":["As you can see, the CoNLL 2000 corpus contains three chunk types: NP chunks, which we have already seen; VP chunks and PP chunks. Since we are only interested in the NP chunks right now, we can use the\n","chunk_types argument to select them:\n","\n","![6.png](attachment:6.png)"]},{"cell_type":"markdown","id":"a265f31a","metadata":{"id":"a265f31a"},"source":["# Simple Evaluation and Baselines\n","\n","Now that we can access a chunked corpus, we can evaluate chunkers. We start off by establishing a baseline for the trivial chunk parser cp that creates no chunks:\n","\n","Expected output from the following code:\n","\n","![7.png](attachment:7.png)\n","\n","The IOB tag accuracy indicates that more than a third of the words are tagged with O, i.e. not in an NP chunk. However, since our tagger\n","did not find any chunks, its precision, recall, and f-measure are all zero.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"df027ce1","metadata":{"id":"df027ce1"},"outputs":[],"source":["from nltk.corpus import conll2000\n","cp = nltk.RegexpParser(\"\")\n","test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n","print(cp.evaluate(test_sents))\n"]},{"cell_type":"markdown","id":"159423f4","metadata":{"id":"159423f4"},"source":["Now let's try a naive regular expression chunker that looks for\n","tags beginning with letters that are characteristic of noun phrase tags (e.g. CD, DT, and JJ).\n","\n","The expected output from the following code is :\n","\n","![8.png](attachment:8.png)\n","    \n","    "]},{"cell_type":"code","execution_count":null,"id":"2171d1b6","metadata":{"id":"2171d1b6"},"outputs":[],"source":["grammar = r\"NP: {<[CDJNP].*>+}\"\n","cp = nltk.RegexpParser(grammar)\n","print(cp.evaluate(test_sents))\n"]},{"cell_type":"markdown","id":"8895d134","metadata":{"id":"8895d134"},"source":["# 4 Recursion in Linguistic Structure"]},{"cell_type":"markdown","id":"dcbd4925","metadata":{"id":"dcbd4925"},"source":["# 4.1 Building Nested Structure with Cascaded Chunkers\n","\n","It is possible to build chunk structures of arbitrary depth, simply by creating a multi-stage chunk grammar containing\n","recursive rules has patterns for noun phrases, prepositional phrases, verb phrases, and sentences. Following exampe is a four-stage chunk\n","grammar, and can be used to create structures having a depth of at most four.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"5903fcbd","metadata":{"id":"5903fcbd","outputId":"a39af54b-fe6b-4c7a-9668-769e82ced5c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  (NP Mary/NN)\n","  saw/VBD\n","  (CLAUSE\n","    (NP the/DT cat/NN)\n","    (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))\n"]}],"source":["import nltk\n","grammar = r\"\"\"\n"," NP: {<DT|JJ|NN.*>+} # Chunk sequences of DT, JJ, NN\n"," PP: {<IN><NP>} # Chunk prepositions followed by NP\n"," VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\n"," CLAUSE: {<NP><VP>} # Chunk NP, VP\n","\"\"\"\n","cp = nltk.RegexpParser(grammar)\n","sentence = [(\"Mary\", \"NN\"), (\"saw\", \"VBD\"), (\"the\", \"DT\"), (\"cat\", \"NN\"),\n"," (\"sit\", \"VB\"), (\"on\", \"IN\"), (\"the\", \"DT\"), (\"mat\", \"NN\")]\n","print(cp.parse(sentence))\n"]},{"cell_type":"markdown","id":"975c7562","metadata":{"id":"975c7562"},"source":["Unfortunately this result misses the VP headed by saw. It has other shortcomings too. Let's see what happens when we apply this\n","chunker to a sentence having deeper nesting. Notice that it fails to identify the VP chunk."]},{"cell_type":"code","execution_count":null,"id":"228828c9","metadata":{"id":"228828c9","outputId":"0d1cb9b6-2232-4e2c-f3f4-87d416694adb"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  (NP John/NNP)\n","  thinks/VBZ\n","  (NP Mary/NN)\n","  saw/VBD\n","  (CLAUSE\n","    (NP the/DT cat/NN)\n","    (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))\n"]}],"source":["sentence = [(\"John\", \"NNP\"), (\"thinks\", \"VBZ\"), (\"Mary\", \"NN\"),\n","(\"saw\", \"VBD\"), (\"the\", \"DT\"), (\"cat\", \"NN\"), (\"sit\", \"VB\"),\n","(\"on\", \"IN\"), (\"the\", \"DT\"), (\"mat\", \"NN\")]\n","print(cp.parse(sentence))\n"]},{"cell_type":"markdown","id":"b041b790","metadata":{"id":"b041b790"},"source":["The solution to these problems is to get the chunker to loop over its patterns: after trying all of them, it repeats the process. We add an\n","optional second argument loop to specify the number of times the set of patterns should be run:\n"]},{"cell_type":"code","execution_count":null,"id":"96200cfa","metadata":{"id":"96200cfa","outputId":"e4684a43-f393-47e1-d549-bbb738efaea6"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  (NP John/NNP)\n","  thinks/VBZ\n","  (CLAUSE\n","    (NP Mary/NN)\n","    (VP\n","      saw/VBD\n","      (CLAUSE\n","        (NP the/DT cat/NN)\n","        (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))))\n"]}],"source":["cp = nltk.RegexpParser(grammar, loop=2)\n","print(cp.parse(sentence))"]},{"cell_type":"markdown","id":"77bfbada","metadata":{"id":"77bfbada"},"source":["# 4.2 Trees\n","\n","A tree is a set of connected labeled nodes, each reachable by a unique path from a distinguished root node. Here's an example of a tree\n","![9.png](attachment:9.png)\n","\n","We use a 'family' metaphor to talk about the relationships of nodes in a tree: for example, S is the parent of VP; conversely VP is a child\n","of S. Also, since NP and VP are both children of S, they are also siblings.\n","\n","Although we will focus on syntactic trees, trees can be used to encode any homogeneous hierarchical structure that spans a sequence of\n","linguistic forms (e.g. morphological structure, discourse structure). In the general case, leaves and node values do not have to be strings.\n","In NLTK, we create a tree by giving a node label and a list of children:\n","\n"]},{"cell_type":"code","execution_count":null,"id":"9a366094","metadata":{"id":"9a366094","outputId":"7bacb728-01b3-4337-ee6f-3e23df9f8b76"},"outputs":[{"name":"stdout","output_type":"stream","text":["(NP Alice)\n"]}],"source":["tree1 = nltk.Tree('NP', ['Alice'])\n","print(tree1)\n"]},{"cell_type":"code","execution_count":null,"id":"899919b4","metadata":{"id":"899919b4","outputId":"8ef630b2-2390-4180-c4bb-c58f59700d74"},"outputs":[{"name":"stdout","output_type":"stream","text":["(NP the rabbit)\n"]}],"source":["tree2 = nltk.Tree('NP', ['the', 'rabbit'])\n","print(tree2)\n"]},{"cell_type":"code","execution_count":null,"id":"fa35898d","metadata":{"id":"fa35898d","outputId":"94cd7a67-5b9a-4f8b-bf04-5b9abe69e0c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S (NP Alice) (VP chased (NP the rabbit)))\n"]}],"source":["tree3 = nltk.Tree('VP', ['chased', tree2])\n","tree4 = nltk.Tree('S', [tree1, tree3])\n","print(tree4)"]},{"cell_type":"code","execution_count":null,"id":"ab158221","metadata":{"id":"ab158221","outputId":"d80972c1-8e89-486e-d2af-dd7f5ae3f75d"},"outputs":[{"name":"stdout","output_type":"stream","text":["(VP chased (NP the rabbit))\n"]}],"source":[" print(tree4[1])\n"]},{"cell_type":"code","execution_count":null,"id":"c3d43e09","metadata":{"id":"c3d43e09","outputId":"253d8d37-9ee4-4220-82df-fe6b948fd165"},"outputs":[{"data":{"text/plain":["'VP'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tree4[1].label()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"8ee544c6","metadata":{"id":"8ee544c6","outputId":"63186e1c-90b5-41e8-ed01-4c9fa789f897"},"outputs":[{"data":{"text/plain":["['Alice', 'chased', 'the', 'rabbit']"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":[" tree4.leaves()\n"]},{"cell_type":"code","execution_count":null,"id":"cbf29f7b","metadata":{"id":"cbf29f7b","outputId":"d17bd299-150b-4339-cf39-7cc9d5369863"},"outputs":[{"data":{"text/plain":["'rabbit'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tree4[1][1][1]"]},{"cell_type":"markdown","id":"ab2b137a","metadata":{"id":"ab2b137a"},"source":["The bracketed representation for complex trees can be difficult to read. In these cases, the draw method can be very useful. It opens a\n","new window, containing a graphical representation of the tree. The tree display window allows you to zoom in and out, to collapse and\n","expand subtrees, and to print the graphical representation to a postscript file (for inclusion in a document)."]},{"cell_type":"code","execution_count":null,"id":"7d88a8c5","metadata":{"id":"7d88a8c5"},"outputs":[],"source":["tree3.draw()"]},{"cell_type":"markdown","id":"6c716b7f","metadata":{"id":"6c716b7f"},"source":["# 4.3 Tree Traversal\n","It is standard to use a recursive function to traverse a tree.  Here is an example of a Recursive Function to Traverse a Tree."]},{"cell_type":"code","execution_count":null,"id":"b731022f","metadata":{"id":"b731022f","outputId":"16506d34-8ff9-4f43-a031-66a61e8622d9"},"outputs":[{"name":"stdout","output_type":"stream","text":[") "]},{"ename":"TypeError","evalue":"Tree: Expected a node value and child list ","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#Define an NLTK tree t representing the structure of a sentence:\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m t \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mTree(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(S (NP Alice) (VP chased (NP the rabbit)))\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#Call the traverse function on the tree t to print the labels of its nodes in a specific format:\u001b[39;00m\n\u001b[0;32m     28\u001b[0m traverse(t)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tree\\tree.py:94\u001b[0m, in \u001b[0;36mTree.__init__\u001b[1;34m(self, node, children)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, children\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m children \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     95\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: Expected a node value and child list \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(children, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() argument 2 should be a list, not a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    101\u001b[0m         )\n","\u001b[1;31mTypeError\u001b[0m: Tree: Expected a node value and child list "]}],"source":["import nltk\n","def traverse(t):\n","\n","#Try to access the label of the current node.\n","#If it's not possible (AttributeError is raised), print the node itself:\n"," try:\n","     t.label()\n"," except AttributeError:\n","     print(t, end=\" \")\n","#If accessing the label is successful, print the opening parenthesis and the label:\n"," else:\n"," # Now we know that t.node is defined\n","     print('(', t.label(), end=\" \")\n","\n","#Iterate through each child of the current node and recursively call\n","#the traverse function for each child:\n"," for child in t:\n","     traverse(child)\n","\n","#After traversing all children, print the closing parenthesis:\n","print(')', end=\" \")\n","\n","#Define an NLTK tree t representing the structure of a sentence:\n","\n","t = nltk.Tree('(S (NP Alice) (VP chased (NP the rabbit)))')\n","\n","#Call the traverse function on the tree t to print the labels of its nodes in a specific format:\n","traverse(t)"]},{"cell_type":"markdown","id":"1d914519","metadata":{"id":"1d914519"},"source":["# 5 Named Entity Recognition\n","At the start of this chapter, we briefly introduced named entities (NEs). Named entities are definite noun phrases that refer to specific\n","types of individuals, such as organizations, persons, dates, and so on. 5.1 lists some of the more commonly used types of NEs. These\n","should be self-explanatory, except for \"Facility\": human-made artifacts in the domains of architecture and civil engineering; and \"GPE\":\n","geo-political entities such as city, state/province, and country.\n","\n","![10.png](attachment:10.png)\n","\n","The goal of a named entity recognition (NER) system is to identify all textual mentions of the named entities. This can be broken\n","down into two sub-tasks: identifying the boundaries of the NE, and identifying its type. While named entity recognition is frequently a\n","prelude to identifying relations in Information Extraction, it can also contribute to other tasks. For example, in Question Answering\n","(QA), we try to improve the precision of Information Retrieval by recovering not whole pages, but just those parts which contain an\n","answer to the user's question. Most QA systems take the documents returned by standard Information Retrieval, and then attempt to\n","isolate the minimal text snippet in the document containing the answer. Now suppose the question was Who was the first President of\n","the US?, and one of the documents that was retrieved contained the following passage:\n","(5) The Washington Monument is the most prominent structure in Washington, D.C. and one of the city's early attractions. It was\n","built in honor of George Washington, who led the country to independence and then became its first President.\n","Analysis of the question leads us to expect that an answer should be of the form X was the first President of the US, where X is not only\n","a noun phrase, but also refers to a named entity of type PERSON. This should allow us to ignore the first sentence in the passage. While\n","it contains two occurrences of Washington, named entity recognition should tell us that neither of them has the correct type.\n","How do we go about identifying named entities? One option would be to look up each word in an appropriate list of names. For\n","example, in the case of locations, we could use a gazetteer, or geographical dictionary, such as the Alexandria Gazetteer or the Getty\n","Gazetteer. However, doing this blindly runs into problems, as shown below:\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"229866ac","metadata":{"id":"229866ac"},"source":["![11.png](attachment:11.png)"]},{"cell_type":"markdown","id":"ad212291","metadata":{"id":"ad212291"},"source":["Observe that the gazetteer has good coverage of locations in many countries, and incorrectly finds locations like Sanchez in the\n","Dominican Republic and On in Vietnam. Of course we could omit such locations from the gazetteer, but then we won't be able to\n","identify them when they do appear in a document.\n","It gets even harder in the case of names for people or organizations. Any list of such names will probably have poor coverage. New\n","organizations come into existence every day, so if we are trying to deal with contemporary newswire or blog entries, it is unlikely that\n","we will be able to recognize many of the entities using gazetteer lookup.\n","Another major source of difficulty is caused by the fact that many named entity terms are ambiguous. Thus May and North are likely to\n","be parts of named entities for DATE and LOCATION, respectively, but could both be part of a PERSON; conversely Christian Dior\n","looks like a PERSON but is more likely to be of type ORGANIZATION. A term like Yankee will be ordinary modifier in some contexts,\n","but will be marked as an entity of type ORGANIZATION in the phrase Yankee infielders.\n","\n","Further challenges are posed by multi-word names like Stanford University, and by names that contain other names such as Cecil H.\n","Green Library and Escondido Village Conference Service Center. In named entity recognition, therefore, we need to be able to identify\n","the beginning and end of multi-token sequences.\n","Named entity recognition is a task that is well-suited to the type of classifier-based approach that we saw for noun phrase chunking. In\n","particular, we can build a tagger that labels each word in a sentence using the IOB format, where chunks are labeled by their appropriate\n","type. Here is part of the CONLL 2002 (conll2002) Dutch training data:\n","\n","    \n","NLTK provides a classifier that has already been trained to recognize named entities, accessed with the function nltk.ne_chunk(). If we\n","set the parameter binary=True , then named entities are just tagged as NE; otherwise, the classifier adds category labels such as\n","PERSON, ORGANIZATION, and GPE.\n"]},{"cell_type":"code","execution_count":null,"id":"b6cfe62e","metadata":{"id":"b6cfe62e","outputId":"75aadc0b-a696-4b09-dedb-b79b2c6e3db1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  The/DT\n","  (NE U.S./NNP)\n","  is/VBZ\n","  one/CD\n","  of/IN\n","  the/DT\n","  few/JJ\n","  industrialized/VBN\n","  nations/NNS\n","  that/WDT\n","  *T*-7/-NONE-\n","  does/VBZ\n","  n't/RB\n","  have/VB\n","  a/DT\n","  higher/JJR\n","  standard/NN\n","  of/IN\n","  regulation/NN\n","  for/IN\n","  the/DT\n","  smooth/JJ\n","  ,/,\n","  needle-like/JJ\n","  fibers/NNS\n","  such/JJ\n","  as/IN\n","  crocidolite/NN\n","  that/WDT\n","  *T*-1/-NONE-\n","  are/VBP\n","  classified/VBN\n","  *-5/-NONE-\n","  as/IN\n","  amphobiles/NNS\n","  ,/,\n","  according/VBG\n","  to/TO\n","  (NE Brooke/NNP)\n","  T./NNP\n","  Mossman/NNP\n","  ,/,\n","  a/DT\n","  professor/NN\n","  of/IN\n","  pathlogy/NN\n","  at/IN\n","  the/DT\n","  (NE University/NNP)\n","  of/IN\n","  (NE Vermont/NNP College/NNP)\n","  of/IN\n","  (NE Medicine/NNP)\n","  ./.)\n"]}],"source":["sent = nltk.corpus.treebank.tagged_sents()[22]\n","print(nltk.ne_chunk(sent, binary=True))"]},{"cell_type":"code","execution_count":null,"id":"cd7e87af","metadata":{"id":"cd7e87af","outputId":"46c61c6a-8fda-4ba7-8ff9-144837c9465c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  The/DT\n","  (GPE U.S./NNP)\n","  is/VBZ\n","  one/CD\n","  of/IN\n","  the/DT\n","  few/JJ\n","  industrialized/VBN\n","  nations/NNS\n","  that/WDT\n","  *T*-7/-NONE-\n","  does/VBZ\n","  n't/RB\n","  have/VB\n","  a/DT\n","  higher/JJR\n","  standard/NN\n","  of/IN\n","  regulation/NN\n","  for/IN\n","  the/DT\n","  smooth/JJ\n","  ,/,\n","  needle-like/JJ\n","  fibers/NNS\n","  such/JJ\n","  as/IN\n","  crocidolite/NN\n","  that/WDT\n","  *T*-1/-NONE-\n","  are/VBP\n","  classified/VBN\n","  *-5/-NONE-\n","  as/IN\n","  amphobiles/NNS\n","  ,/,\n","  according/VBG\n","  to/TO\n","  (PERSON Brooke/NNP T./NNP Mossman/NNP)\n","  ,/,\n","  a/DT\n","  professor/NN\n","  of/IN\n","  pathlogy/NN\n","  at/IN\n","  the/DT\n","  (ORGANIZATION University/NNP)\n","  of/IN\n","  (PERSON Vermont/NNP College/NNP)\n","  of/IN\n","  (GPE Medicine/NNP)\n","  ./.)\n"]}],"source":[" print(nltk.ne_chunk(sent))\n"]},{"cell_type":"markdown","id":"5baa1d52","metadata":{"id":"5baa1d52"},"source":["# 6 Relation Extraction\n","\n","Once named entities have been identified in a text, we then want to extract the relations that exist between them. As indicated earlier,\n","we will typically be looking for relations between specified types of named entity. One way of approaching this task is to initially look\n","for all triples of the form (X, α, Y), where X and Y are named entities of the required types, and α is the string of words that intervenes\n","between X and Y. We can then use regular expressions to pull out just those instances of α that express the relation that we are looking\n","for. The following example searches for strings that contain the word in. The special regular expression (?!\\b.+ing\\b) is a negative\n","lookahead assertion that allows us to disregard strings such as success in supervising the transition of, where in is followed by a gerund.\n"]},{"cell_type":"code","execution_count":null,"id":"fc91e10b","metadata":{"id":"fc91e10b","outputId":"cd4fbb84-34e7-4853-8959-3e157c6c04c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']\n","[ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']\n","[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']\n","[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']\n","[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']\n","[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']\n","[ORG: 'WGBH'] 'in' [LOC: 'Boston']\n","[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']\n","[ORG: 'Omnicom'] 'in' [LOC: 'New York']\n","[ORG: 'DDB Needham'] 'in' [LOC: 'New York']\n","[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']\n","[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']\n","[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']\n"]}],"source":["import nltk, re, pprint\n","IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n","for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n","    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc,\n","        corpus='ieer', pattern = IN):\n","        print(nltk.sem.rtuple(rel))"]},{"cell_type":"markdown","id":"ccac1cb8","metadata":{"id":"ccac1cb8"},"source":["Searching for the keyword in works reasonably well, though it will also retrieve false positives such as [ORG: House\n","Transportation Committee] , secured the most money in the [LOC: New\n","York]; there is unlikely to be simple string-based method of excluding filler strings such as this.\n","As shown above, the conll2002 Dutch corpus contains not just named entity annotation but also part-of-speech tags. This allows us to\n","devise patterns that are sensitive to these tags, as shown in the next example. The method clause() prints out the relations in a clausal\n","form, where the binary relation symbol is specified as the value of parameter relsym"]},{"cell_type":"code","execution_count":null,"id":"1e343ba9","metadata":{"id":"1e343ba9","outputId":"069c1225-4235-4633-e84b-a45ab304fa55"},"outputs":[{"name":"stdout","output_type":"stream","text":["VAN(\"cornet_d'elzius\", 'buitenlandse_handel')\n","VAN('johan_rottiers', 'kardinaal_van_roey_instituut')\n","VAN('annie_lennox', 'eurythmics')\n"]}],"source":["import nltk, re, pprint\n","from nltk.corpus import conll2002\n","vnv = \"\"\"\n","(\n","is/V| # 3rd sing present and\n","was/V| # past forms of the verb zijn ('be')\n","werd/V| # and also present\n","wordt/V # past of worden ('become)\n",")\n",".* # followed by anything\n","van/Prep # followed by van ('of')\n","\"\"\"\n","VAN = re.compile(vnv, re.VERBOSE)\n","for doc in conll2002.chunked_sents('ned.train'):\n","    for rel in nltk.sem.extract_rels('PER', 'ORG', doc,corpus='conll2002', pattern=VAN):\n","        print(nltk.sem.clause(rel, relsym=\"VAN\"))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}